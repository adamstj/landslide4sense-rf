{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process the landslide4sense training images\n",
    "\n",
    "This script reads the downloaded landslide4sense training images, calculates new indexes such as NDVI and outputs .npy files. The shell of this script have been borrowed by @iamtekson and modified to fit my needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the 3799 training images and labels and assign them to 4d numpy arrays\n",
    "TRAIN_PATH = r\"\\landslide4sense\\img\\*.h5\"\n",
    "TRAIN_MASK = r\"\\landslide4sense\\mask\\*.h5\"\n",
    "\n",
    "TRAIN_XX = np.zeros((3799, 128, 128, 11))\n",
    "TRAIN_YY = np.zeros((3799, 128, 128, 1))\n",
    "all_train = sorted(glob.glob(TRAIN_PATH))\n",
    "all_mask = sorted(glob.glob(TRAIN_MASK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read images, calculate bands and create two numpy arrays, X and y\n",
    "for i, (img, mask) in enumerate(zip(all_train, all_mask)):\n",
    "    with h5py.File(img) as hdf:\n",
    "        ls = list(hdf.keys())\n",
    "        data = np.array(hdf.get('img'))\n",
    "\n",
    "        # assign 0 for the nan value\n",
    "        data[np.isnan(data)] = 0.000001\n",
    "\n",
    "        # to normalize the data \n",
    "        mid_rgb = data[:, :, 1:4].max() / 2.0\n",
    "        mid_slope = data[:, :, 12].max() / 2.0\n",
    "        mid_elevation = data[:, :, 13].max() / 2.0\n",
    "        mid_b10 = data[:, :, 10].max() / 2.0\n",
    "\n",
    "        # ndvi calculation\n",
    "        data_red = data[:, :, 3]\n",
    "        data_nir = data[:, :, 7]\n",
    "        data_ndvi = np.divide(data_nir - data_red,np.add(data_nir, data_red))\n",
    "\n",
    "        # ndmi calculation\n",
    "        b7 = data[:, :, 7]\n",
    "        b10 = data[:, :, 10]\n",
    "        data_ndmi = np.divide(b7 - b10, np.add(b7, b10))\n",
    "\n",
    "        # gndvi calculation\n",
    "        b2 = data[:, :, 2]\n",
    "        data_gndvi = np.divide(b7 - b2, np.add(b7, b2))\n",
    "        \n",
    "        # brightness calculation\n",
    "        b3 = data[:, :, 3]\n",
    "        data_br = np.sqrt(np.divide(np.divide(np.multiply(b3, b3),np.multiply(b2, b2)), 2))\n",
    "        mid_br = data_br.max() / 2.0\n",
    "\n",
    "        # bsi calculation\n",
    "        b1 = data[:, :, 1]\n",
    "        data_bsi = np.divide((np.add(b10,b3) - np.add(b7, b1)), np.add(np.add(b10, b3), np.add(b7,b1)))\n",
    "        data_bsi_norm = (data_bsi-data_bsi.min()) / (data_bsi.max()-data_bsi.min())\n",
    "        \n",
    "        # final array\n",
    "        TRAIN_XX[i, :, :, 0] = 1 - data[:, :, 3] / mid_rgb  #RED\n",
    "        TRAIN_XX[i, :, :, 1] = 1 - data[:, :, 2] / mid_rgb #GREEN\n",
    "        TRAIN_XX[i, :, :, 2] = 1 - data[:, :, 1] / mid_rgb #BLUE\n",
    "        TRAIN_XX[i, :, :, 3] = data_ndvi #NDVI\n",
    "        TRAIN_XX[i, :, :, 4] = 1 - data[:, :, 12] / mid_slope #SLOPE\n",
    "        TRAIN_XX[i, :, :, 5] = 1 - data[:, :, 13] / mid_elevation #ELEVATION\n",
    "        TRAIN_XX[i, :, :, 6] = data_ndmi #NDMI\n",
    "        TRAIN_XX[i, :, :, 7] = data_gndvi #GNDVI\n",
    "        TRAIN_XX[i, :, :, 8] = 1 - data[:, :, 10] / mid_b10 #BAND 10\n",
    "        TRAIN_XX[i, :, :, 9] = 1 - data_br / mid_br #BRIGHTNESS\n",
    "        TRAIN_XX[i, :, :, 10] = 1 - data_bsi_norm #BSI\n",
    "    \n",
    "    \n",
    "    with h5py.File(mask) as hdf:\n",
    "        ls = list(hdf.keys())\n",
    "        data=np.array(hdf.get('mask'))\n",
    "        TRAIN_YY[i, :, :, 0] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#Check the min, max for ensuring normalized data within -1.0 - 1.0\n",
    "TRAIN_XX[np.isnan(TRAIN_XX)] = 0.000001\n",
    "print(TRAIN_XX.min(), TRAIN_XX.max(), TRAIN_YY.min(), TRAIN_YY.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the arrays\n",
    "np.save('output/TRAIN_XX_11var.npy', TRAIN_XX)\n",
    "np.save('output/TRAIN_YY_11var.npy', TRAIN_YY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('rs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "717d1a099d821e3a78c05d45a80ec65f2fc2a9c12b055f1677373fd3b0a41632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
